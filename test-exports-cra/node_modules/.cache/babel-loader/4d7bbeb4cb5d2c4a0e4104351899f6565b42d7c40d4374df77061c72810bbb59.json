{"ast":null,"code":"var _jsxFileName = \"/Users/b/Code/langchainjs/test-exports-cra/src/App.js\",\n  _s = $RefreshSig$();\n/* eslint-disable no-unused-vars */\n\n// import all entrypoints to test, do not do this in your own app\nimport \"./entrypoints.js\";\n\n// Import a few things we'll use to test the exports\nimport { LLMChain } from \"langchain/chains\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport { ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate } from \"langchain/prompts\";\nimport { useCallback, useEffect, useState } from \"react\";\nimport { CallbackManager } from \"langchain/callbacks\";\nimport { WindowAi, ModelID } from \"./WindowAi.ts\";\nimport { DynamicTool } from \"langchain/tools\";\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { initializeAgentExecutor, ZapierToolKit, OpenApiToolkit } from \"langchain/agents\";\nimport { ZapierNLAWrapper } from \"langchain/tools\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nfunction App() {\n  _s();\n  const [input, setInput] = useState(\"\");\n  const [llmResponses, setLlmResponses] = useState([]);\n  const [modelInUse, setModelInUse] = useState(\"\");\n  const handleSubmit = useCallback(async event => {\n    event.preventDefault(); // prevent the default form submission behavior\n    // Use the user input if available, otherwise use a default question\n    const question = input ? input : \"No question entered by user\";\n    // Create the LLM chain\n    const llm = new WindowAi({\n      completionOptions: {\n        temperature: 0.7,\n        maxTokens: 800,\n        model: ModelID.GPT3\n      }\n    });\n    const template = `Question: {question}.  Answer: Let's think step by step.`;\n    const prompt = new PromptTemplate({\n      template: template,\n      inputVariables: [\"question\"]\n    });\n    const llm_chain = new LLMChain({\n      prompt: prompt,\n      llm: llm\n    });\n    // Run the LLM chain\n    const response = await llm_chain.run(input);\n    // Update the state variables\n    const model = await llm.getCurrentModel();\n    setModelInUse(model);\n    setLlmResponses(prevResponses => [...prevResponses, response]);\n    // Clear the input field\n    setInput(\"\");\n  }, [input]);\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: /*#__PURE__*/_jsxDEV(\"header\", {\n      className: \"App-header\",\n      children: [/*#__PURE__*/_jsxDEV(\"h1\", {\n        children: \"WindowAi Langchain Demo\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 60,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: modelInUse ? \"model detected\" : \"model\",\n        style: {\n          color: modelInUse ? \"green\" : \"#555\"\n        },\n        children: [\"Model in use: \", modelInUse ? modelInUse : \"not yet detected\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 61,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n        className: \"subheader\",\n        children: \"Ask a question and let WindowAi guide you through the reasoning process step by step.\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 63,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"a\", {\n        className: \"logo\",\n        href: \"https://windowai.io\",\n        target: \"_blank\",\n        rel: \"noopener noreferrer\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 64,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"form\", {\n        onSubmit: handleSubmit,\n        children: [/*#__PURE__*/_jsxDEV(\"label\", {\n          children: /*#__PURE__*/_jsxDEV(\"input\", {\n            type: \"text\",\n            className: \"input\",\n            value: input,\n            onChange: e => setInput(e.target.value),\n            placeholder: \" Type your question\"\n          }, void 0, false, {\n            fileName: _jsxFileName,\n            lineNumber: 67,\n            columnNumber: 13\n          }, this)\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 66,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n          type: \"submit\",\n          className: \"button\",\n          children: \"Submit\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 69,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 65,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"responses\",\n        children: llmResponses.map((response, index) => /*#__PURE__*/_jsxDEV(\"p\", {\n          className: \"response\",\n          children: response\n        }, index, false, {\n          fileName: _jsxFileName,\n          lineNumber: 74,\n          columnNumber: 13\n        }, this))\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 72,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 59,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 58,\n    columnNumber: 5\n  }, this);\n}\n\n// const run = async () => {\n//   const model = new OpenAI({ temperature: 0, openAIApiKey: \"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\"});\n_s(App, \"bXKh3qbSmtsPbN4yBCtdESsgakc=\");\n_c = App;\nconst run = async () => {\n  // const model = new OpenAI({ temperature: 0 });\n  var llm = new WindowAi({\n    completionOptions: {\n      temperature: 0.7,\n      maxTokens: 800,\n      model: ModelID.GPT3\n    }\n  });\n  // const zapier = new ZapierNLAWrapper();\n  // const toolkit = await ZapierToolKit.fromZapierNLAWrapper(zapier);\n  const toolkit = await OpenApiToolkit({\n    llm: llm\n  });\n  const executor = await initializeAgentExecutor(toolkit.tools, llm, \"zero-shot-react-description\", true);\n  console.log(\"Loaded agent.\");\n  const input = `Summarize the last email I received regarding Silicon Valley Bank. Send the summary to the #test-zapier Slack channel.`;\n  console.log(`Executing with input \"${input}\"...`);\n  const result = await executor.call({\n    input\n  });\n  console.log(`Got output ${result.output}`);\n};\n\n// };\n\nrun();\nexport default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["LLMChain","ChatOpenAI","ChatPromptTemplate","HumanMessagePromptTemplate","PromptTemplate","useCallback","useEffect","useState","CallbackManager","WindowAi","ModelID","DynamicTool","OpenAI","initializeAgentExecutor","ZapierToolKit","OpenApiToolkit","ZapierNLAWrapper","jsxDEV","_jsxDEV","App","_s","input","setInput","llmResponses","setLlmResponses","modelInUse","setModelInUse","handleSubmit","event","preventDefault","question","llm","completionOptions","temperature","maxTokens","model","GPT3","template","prompt","inputVariables","llm_chain","response","run","getCurrentModel","prevResponses","className","children","fileName","_jsxFileName","lineNumber","columnNumber","style","color","href","target","rel","onSubmit","type","value","onChange","e","placeholder","map","index","_c","toolkit","executor","tools","console","log","result","call","output","$RefreshReg$"],"sources":["/Users/b/Code/langchainjs/test-exports-cra/src/App.js"],"sourcesContent":["/* eslint-disable no-unused-vars */\n\n// import all entrypoints to test, do not do this in your own app\nimport \"./entrypoints.js\";\n\n// Import a few things we'll use to test the exports\nimport { LLMChain } from \"langchain/chains\";\nimport { ChatOpenAI } from \"langchain/chat_models/openai\";\nimport {\n  ChatPromptTemplate,\n  HumanMessagePromptTemplate,\n  PromptTemplate\n} from \"langchain/prompts\";\n\n\nimport { useCallback, useEffect, useState } from \"react\";\nimport { CallbackManager } from \"langchain/callbacks\";\n\nimport { WindowAi, ModelID } from \"./WindowAi.ts\"\n\n\nimport { DynamicTool } from \"langchain/tools\";\n\nimport { OpenAI } from \"langchain/llms/openai\";\nimport { initializeAgentExecutor, ZapierToolKit, OpenApiToolkit } from \"langchain/agents\";\nimport { ZapierNLAWrapper } from \"langchain/tools\";\n\nfunction App() {\n  const [input, setInput] = useState(\"\");\n  const [llmResponses, setLlmResponses] = useState([]);\n  const [modelInUse, setModelInUse] = useState(\"\");\n\n  const handleSubmit = useCallback(\n    async (event) => {\n      event.preventDefault(); // prevent the default form submission behavior\n      // Use the user input if available, otherwise use a default question\n      const question = input ? input : \"No question entered by user\";\n      // Create the LLM chain\n      const llm = new WindowAi({ completionOptions: { temperature: 0.7, maxTokens: 800, model: ModelID.GPT3 } });\n      const template = `Question: {question}.  Answer: Let's think step by step.`;\n      const prompt = new PromptTemplate({ template:template, inputVariables:[\"question\"] });\n     \n\n      const llm_chain = new LLMChain({ prompt:prompt, llm:llm });\n      // Run the LLM chain\n      const response = await llm_chain.run(input);\n      // Update the state variables\n      const model = await llm.getCurrentModel();\n      setModelInUse(model);\n      setLlmResponses((prevResponses) => [...prevResponses, response]);\n      // Clear the input field\n      setInput(\"\");\n    },\n    [input]\n  );\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <h1>WindowAi Langchain Demo</h1>\n        <p className={modelInUse ? \"model detected\" : \"model\"} style={{ color: modelInUse ? \"green\" : \"#555\" }}>Model in use: {modelInUse ? modelInUse : \"not yet detected\"}</p>\n\n        <p className=\"subheader\">Ask a question and let WindowAi guide you through the reasoning process step by step.</p>\n        <a className=\"logo\" href=\"https://windowai.io\" target=\"_blank\" rel=\"noopener noreferrer\"></a>\n        <form onSubmit={handleSubmit}>\n          <label>\n            <input type=\"text\" className=\"input\" value={input} onChange={(e) => setInput(e.target.value)} placeholder=\" Type your question\" />\n          </label>\n          <button type=\"submit\" className=\"button\">Submit</button>\n        </form>\n    \n        <div className=\"responses\">\n          {llmResponses.map((response, index) => (\n            <p key={index} className=\"response\">{response}</p>\n          ))}\n        </div>\n      </header>\n    </div>\n  );\n }\n\n// const run = async () => {\n//   const model = new OpenAI({ temperature: 0, openAIApiKey: \"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\"});\nconst run = async () => {\n    // const model = new OpenAI({ temperature: 0 });\n    var llm = new WindowAi({ completionOptions: { temperature: 0.7, maxTokens: 800, model: ModelID.GPT3 } })\n    // const zapier = new ZapierNLAWrapper();\n    // const toolkit = await ZapierToolKit.fromZapierNLAWrapper(zapier);\n    const toolkit = await OpenApiToolkit({llm: llm})\n\n  \n    const executor = await initializeAgentExecutor(\n      toolkit.tools,\n      llm,\n      \"zero-shot-react-description\",\n      true\n    );\n    console.log(\"Loaded agent.\");\n  \n    const input = `Summarize the last email I received regarding Silicon Valley Bank. Send the summary to the #test-zapier Slack channel.`;\n  \n    console.log(`Executing with input \"${input}\"...`);\n  \n    const result = await executor.call({ input });\n  \n    console.log(`Got output ${result.output}`);\n  };\n\n// };\n\nrun()\n\nexport default App;\n"],"mappings":";;AAAA;;AAEA;AACA,OAAO,kBAAkB;;AAEzB;AACA,SAASA,QAAQ,QAAQ,kBAAkB;AAC3C,SAASC,UAAU,QAAQ,8BAA8B;AACzD,SACEC,kBAAkB,EAClBC,0BAA0B,EAC1BC,cAAc,QACT,mBAAmB;AAG1B,SAASC,WAAW,EAAEC,SAAS,EAAEC,QAAQ,QAAQ,OAAO;AACxD,SAASC,eAAe,QAAQ,qBAAqB;AAErD,SAASC,QAAQ,EAAEC,OAAO,QAAQ,eAAe;AAGjD,SAASC,WAAW,QAAQ,iBAAiB;AAE7C,SAASC,MAAM,QAAQ,uBAAuB;AAC9C,SAASC,uBAAuB,EAAEC,aAAa,EAAEC,cAAc,QAAQ,kBAAkB;AACzF,SAASC,gBAAgB,QAAQ,iBAAiB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEnD,SAASC,GAAGA,CAAA,EAAG;EAAAC,EAAA;EACb,MAAM,CAACC,KAAK,EAAEC,QAAQ,CAAC,GAAGf,QAAQ,CAAC,EAAE,CAAC;EACtC,MAAM,CAACgB,YAAY,EAAEC,eAAe,CAAC,GAAGjB,QAAQ,CAAC,EAAE,CAAC;EACpD,MAAM,CAACkB,UAAU,EAAEC,aAAa,CAAC,GAAGnB,QAAQ,CAAC,EAAE,CAAC;EAEhD,MAAMoB,YAAY,GAAGtB,WAAW,CAC9B,MAAOuB,KAAK,IAAK;IACfA,KAAK,CAACC,cAAc,EAAE,CAAC,CAAC;IACxB;IACA,MAAMC,QAAQ,GAAGT,KAAK,GAAGA,KAAK,GAAG,6BAA6B;IAC9D;IACA,MAAMU,GAAG,GAAG,IAAItB,QAAQ,CAAC;MAAEuB,iBAAiB,EAAE;QAAEC,WAAW,EAAE,GAAG;QAAEC,SAAS,EAAE,GAAG;QAAEC,KAAK,EAAEzB,OAAO,CAAC0B;MAAK;IAAE,CAAC,CAAC;IAC1G,MAAMC,QAAQ,GAAI,0DAAyD;IAC3E,MAAMC,MAAM,GAAG,IAAIlC,cAAc,CAAC;MAAEiC,QAAQ,EAACA,QAAQ;MAAEE,cAAc,EAAC,CAAC,UAAU;IAAE,CAAC,CAAC;IAGrF,MAAMC,SAAS,GAAG,IAAIxC,QAAQ,CAAC;MAAEsC,MAAM,EAACA,MAAM;MAAEP,GAAG,EAACA;IAAI,CAAC,CAAC;IAC1D;IACA,MAAMU,QAAQ,GAAG,MAAMD,SAAS,CAACE,GAAG,CAACrB,KAAK,CAAC;IAC3C;IACA,MAAMc,KAAK,GAAG,MAAMJ,GAAG,CAACY,eAAe,EAAE;IACzCjB,aAAa,CAACS,KAAK,CAAC;IACpBX,eAAe,CAAEoB,aAAa,IAAK,CAAC,GAAGA,aAAa,EAAEH,QAAQ,CAAC,CAAC;IAChE;IACAnB,QAAQ,CAAC,EAAE,CAAC;EACd,CAAC,EACD,CAACD,KAAK,CAAC,CACR;EAED,oBACEH,OAAA;IAAK2B,SAAS,EAAC,KAAK;IAAAC,QAAA,eAClB5B,OAAA;MAAQ2B,SAAS,EAAC,YAAY;MAAAC,QAAA,gBAC5B5B,OAAA;QAAA4B,QAAA,EAAI;MAAuB;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAAK,eAChChC,OAAA;QAAG2B,SAAS,EAAEpB,UAAU,GAAG,gBAAgB,GAAG,OAAQ;QAAC0B,KAAK,EAAE;UAAEC,KAAK,EAAE3B,UAAU,GAAG,OAAO,GAAG;QAAO,CAAE;QAAAqB,QAAA,GAAC,gBAAc,EAACrB,UAAU,GAAGA,UAAU,GAAG,kBAAkB;MAAA;QAAAsB,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAAK,eAExKhC,OAAA;QAAG2B,SAAS,EAAC,WAAW;QAAAC,QAAA,EAAC;MAAqF;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAAI,eAClHhC,OAAA;QAAG2B,SAAS,EAAC,MAAM;QAACQ,IAAI,EAAC,qBAAqB;QAACC,MAAM,EAAC,QAAQ;QAACC,GAAG,EAAC;MAAqB;QAAAR,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAAK,eAC7FhC,OAAA;QAAMsC,QAAQ,EAAE7B,YAAa;QAAAmB,QAAA,gBAC3B5B,OAAA;UAAA4B,QAAA,eACE5B,OAAA;YAAOuC,IAAI,EAAC,MAAM;YAACZ,SAAS,EAAC,OAAO;YAACa,KAAK,EAAErC,KAAM;YAACsC,QAAQ,EAAGC,CAAC,IAAKtC,QAAQ,CAACsC,CAAC,CAACN,MAAM,CAACI,KAAK,CAAE;YAACG,WAAW,EAAC;UAAqB;YAAAd,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA;QAAG;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,QAC5H,eACRhC,OAAA;UAAQuC,IAAI,EAAC,QAAQ;UAACZ,SAAS,EAAC,QAAQ;UAAAC,QAAA,EAAC;QAAM;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,QAAS;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QACnD,eAEPhC,OAAA;QAAK2B,SAAS,EAAC,WAAW;QAAAC,QAAA,EACvBvB,YAAY,CAACuC,GAAG,CAAC,CAACrB,QAAQ,EAAEsB,KAAK,kBAChC7C,OAAA;UAAe2B,SAAS,EAAC,UAAU;UAAAC,QAAA,EAAEL;QAAQ,GAArCsB,KAAK;UAAAhB,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,QACd;MAAC;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QACE;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EACC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,QACL;AAET;;AAED;AACA;AAAA9B,EAAA,CAvDSD,GAAG;AAAA6C,EAAA,GAAH7C,GAAG;AAwDZ,MAAMuB,GAAG,GAAG,MAAAA,CAAA,KAAY;EACpB;EACA,IAAIX,GAAG,GAAG,IAAItB,QAAQ,CAAC;IAAEuB,iBAAiB,EAAE;MAAEC,WAAW,EAAE,GAAG;MAAEC,SAAS,EAAE,GAAG;MAAEC,KAAK,EAAEzB,OAAO,CAAC0B;IAAK;EAAE,CAAC,CAAC;EACxG;EACA;EACA,MAAM6B,OAAO,GAAG,MAAMlD,cAAc,CAAC;IAACgB,GAAG,EAAEA;EAAG,CAAC,CAAC;EAGhD,MAAMmC,QAAQ,GAAG,MAAMrD,uBAAuB,CAC5CoD,OAAO,CAACE,KAAK,EACbpC,GAAG,EACH,6BAA6B,EAC7B,IAAI,CACL;EACDqC,OAAO,CAACC,GAAG,CAAC,eAAe,CAAC;EAE5B,MAAMhD,KAAK,GAAI,wHAAuH;EAEtI+C,OAAO,CAACC,GAAG,CAAE,yBAAwBhD,KAAM,MAAK,CAAC;EAEjD,MAAMiD,MAAM,GAAG,MAAMJ,QAAQ,CAACK,IAAI,CAAC;IAAElD;EAAM,CAAC,CAAC;EAE7C+C,OAAO,CAACC,GAAG,CAAE,cAAaC,MAAM,CAACE,MAAO,EAAC,CAAC;AAC5C,CAAC;;AAEH;;AAEA9B,GAAG,EAAE;AAEL,eAAevB,GAAG;AAAC,IAAA6C,EAAA;AAAAS,YAAA,CAAAT,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}