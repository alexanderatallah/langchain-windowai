{"ast":null,"code":"var _jsxFileName = \"/Users/b/Code/langchainjs/test-exports-cra/src/App.js\",\n  _s = $RefreshSig$();\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\n/* eslint-disable no-unused-vars */function App() {\n  _s();\n  const [input, setInput] = useState(\"\");\n  // llm_res = useState()\n  const [llmResponses, setLlmResponses] = useState([]);\n  const [modelInUse, setModelInUse] = useState(\"\");\n  // turn llm_res into an array\n  // llm_res = [llm_res, setLlm_res] = useState();\n  const runChain = useCallback(async () => {\n    // WindowAi._ensureAiAvailable()\n\n    const llm = new WindowAi({\n      completionOptions: {\n        temperature: 0.7,\n        maxTokens: 800,\n        model: ModelID.GPT3\n      }\n    });\n    const template = `Question: {question}.  Answer: Let's think step by step.`;\n    const prompt = new PromptTemplate({\n      template: template,\n      inputVariables: [\"question\"]\n    });\n    const llm_chain = new LLMChain({\n      prompt: prompt,\n      llm: llm\n    });\n    const question = \"What NFL team won the Super Bowl in the year lebron was born?\";\n    const response = await llm_chain.run(input !== null && input !== void 0 ? input : question);\n    const model = await llm.getCurrentModel(); //returns 'openai/gpt3.5' for example\n    setModelInUse(model);\n    //  console.log(\"model in use:\", model)\n\n    setLlmResponses(llm_responses => [...llm_responses, response]);\n  }, []);\n\n  //take input from user\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"App\",\n    children: /*#__PURE__*/_jsxDEV(\"header\", {\n      className: \"App-header\",\n      children: [/*#__PURE__*/_jsxDEV(\"p\", {\n        children: [\"Edit \", /*#__PURE__*/_jsxDEV(\"code\", {\n          children: \"src/App.js\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 37,\n          columnNumber: 16\n        }, this), \" and save to reload.\"]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 36,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"a\", {\n        className: \"App-link\",\n        href: \"https://reactjs.org\",\n        target: \"_blank\",\n        rel: \"noopener noreferrer\",\n        children: \"Learn React\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 39,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"input\", {\n        type: \"text\",\n        onChange: e => setInput(e.target.value)\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 47,\n        columnNumber: 9\n      }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n        onClick: runChain,\n        children: \"Click to run a chain\"\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 48,\n        columnNumber: 9\n      }, this), llmResponses.map((response, index) => /*#__PURE__*/_jsxDEV(\"p\", {\n        children: response\n      }, index, false, {\n        fileName: _jsxFileName,\n        lineNumber: 50,\n        columnNumber: 11\n      }, this))]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 35,\n      columnNumber: 7\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 34,\n    columnNumber: 5\n  }, this);\n}\n_s(App, \"4vYf/TZt8X2D73yBbOR8xpiejhs=\");\n_c = App;\nexport default App;\nvar _c;\n$RefreshReg$(_c, \"App\");","map":{"version":3,"names":["App","_s","input","setInput","useState","llmResponses","setLlmResponses","modelInUse","setModelInUse","runChain","useCallback","llm","WindowAi","completionOptions","temperature","maxTokens","model","ModelID","GPT3","template","prompt","PromptTemplate","inputVariables","llm_chain","LLMChain","question","response","run","getCurrentModel","llm_responses","_jsxDEV","className","children","fileName","_jsxFileName","lineNumber","columnNumber","href","target","rel","type","onChange","e","value","onClick","map","index","_c","$RefreshReg$"],"sources":["/Users/b/Code/langchainjs/test-exports-cra/src/App.js"],"sourcesContent":["/* eslint-disable no-unused-vars */function App() {\n\n  const [input, setInput] = useState(\"\");\n  // llm_res = useState()\n  const [llmResponses, setLlmResponses] = useState([]);\n  const[ modelInUse, setModelInUse] = useState(\"\")\n  // turn llm_res into an array\n  // llm_res = [llm_res, setLlm_res] = useState();\n  const runChain = useCallback(async () => {\n\n        // WindowAi._ensureAiAvailable()\n\n        const llm = new WindowAi({  completionOptions : { temperature: 0.7, maxTokens: 800, model: ModelID.GPT3 } });\n        const template = `Question: {question}.  Answer: Let's think step by step.`\n        const prompt = new PromptTemplate({ template:template, inputVariables:[\"question\"]})\n        const llm_chain = new LLMChain({ prompt:prompt, llm:llm})\n        const question = \"What NFL team won the Super Bowl in the year lebron was born?\"\n        const response = await llm_chain.run(input ?? question)\n\n      const model = await llm.getCurrentModel() //returns 'openai/gpt3.5' for example\n      setModelInUse(model)\n    //  console.log(\"model in use:\", model)\n\n      setLlmResponses(llm_responses => [...llm_responses, response]);\n\n\n  }, []);\n\n  //take input from user\n\n\n\n  return (\n    <div className=\"App\">\n      <header className=\"App-header\">\n        <p>\n          Edit <code>src/App.js</code> and save to reload.\n        </p>\n        <a\n          className=\"App-link\"\n          href=\"https://reactjs.org\"\n          target=\"_blank\"\n          rel=\"noopener noreferrer\"\n        >\n          Learn React\n        </a>\n        <input type=\"text\" onChange={(e) => setInput(e.target.value)} />\n        <button onClick={runChain}>Click to run a chain</button>\n        {llmResponses.map((response, index) => (\n          <p key={index}>{response}</p>\n        ))}\n      </header>\n    </div>\n  );\n}\n\nexport default App;"],"mappings":";;;AAAA,mCAAmC,SAASA,GAAGA,CAAA,EAAG;EAAAC,EAAA;EAEhD,MAAM,CAACC,KAAK,EAAEC,QAAQ,CAAC,GAAGC,QAAQ,CAAC,EAAE,CAAC;EACtC;EACA,MAAM,CAACC,YAAY,EAAEC,eAAe,CAAC,GAAGF,QAAQ,CAAC,EAAE,CAAC;EACpD,MAAK,CAAEG,UAAU,EAAEC,aAAa,CAAC,GAAGJ,QAAQ,CAAC,EAAE,CAAC;EAChD;EACA;EACA,MAAMK,QAAQ,GAAGC,WAAW,CAAC,YAAY;IAEnC;;IAEA,MAAMC,GAAG,GAAG,IAAIC,QAAQ,CAAC;MAAGC,iBAAiB,EAAG;QAAEC,WAAW,EAAE,GAAG;QAAEC,SAAS,EAAE,GAAG;QAAEC,KAAK,EAAEC,OAAO,CAACC;MAAK;IAAE,CAAC,CAAC;IAC5G,MAAMC,QAAQ,GAAI,0DAAyD;IAC3E,MAAMC,MAAM,GAAG,IAAIC,cAAc,CAAC;MAAEF,QAAQ,EAACA,QAAQ;MAAEG,cAAc,EAAC,CAAC,UAAU;IAAC,CAAC,CAAC;IACpF,MAAMC,SAAS,GAAG,IAAIC,QAAQ,CAAC;MAAEJ,MAAM,EAACA,MAAM;MAAET,GAAG,EAACA;IAAG,CAAC,CAAC;IACzD,MAAMc,QAAQ,GAAG,+DAA+D;IAChF,MAAMC,QAAQ,GAAG,MAAMH,SAAS,CAACI,GAAG,CAACzB,KAAK,aAALA,KAAK,cAALA,KAAK,GAAIuB,QAAQ,CAAC;IAEzD,MAAMT,KAAK,GAAG,MAAML,GAAG,CAACiB,eAAe,EAAE,EAAC;IAC1CpB,aAAa,CAACQ,KAAK,CAAC;IACtB;;IAEEV,eAAe,CAACuB,aAAa,IAAI,CAAC,GAAGA,aAAa,EAAEH,QAAQ,CAAC,CAAC;EAGlE,CAAC,EAAE,EAAE,CAAC;;EAEN;;EAIA,oBACEI,OAAA;IAAKC,SAAS,EAAC,KAAK;IAAAC,QAAA,eAClBF,OAAA;MAAQC,SAAS,EAAC,YAAY;MAAAC,QAAA,gBAC5BF,OAAA;QAAAE,QAAA,GAAG,OACI,eAAAF,OAAA;UAAAE,QAAA,EAAM;QAAU;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,QAAO,wBAC9B;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAAI,eACJN,OAAA;QACEC,SAAS,EAAC,UAAU;QACpBM,IAAI,EAAC,qBAAqB;QAC1BC,MAAM,EAAC,QAAQ;QACfC,GAAG,EAAC,qBAAqB;QAAAP,QAAA,EAC1B;MAED;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAAI,eACJN,OAAA;QAAOU,IAAI,EAAC,MAAM;QAACC,QAAQ,EAAGC,CAAC,IAAKvC,QAAQ,CAACuC,CAAC,CAACJ,MAAM,CAACK,KAAK;MAAE;QAAAV,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAAG,eAChEN,OAAA;QAAQc,OAAO,EAAEnC,QAAS;QAAAuB,QAAA,EAAC;MAAoB;QAAAC,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QAAS,EACvD/B,YAAY,CAACwC,GAAG,CAAC,CAACnB,QAAQ,EAAEoB,KAAK,kBAChChB,OAAA;QAAAE,QAAA,EAAgBN;MAAQ,GAAhBoB,KAAK;QAAAb,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,QACd,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA;EACK;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,QACL;AAEV;AAACnC,EAAA,CAtD2CD,GAAG;AAAA+C,EAAA,GAAH/C,GAAG;AAwD/C,eAAeA,GAAG;AAAC,IAAA+C,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}